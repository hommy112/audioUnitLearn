```  
  /**    @property    scheduleMIDIEventBlock
        @brief        Block used to schedule MIDI events.
        @discussion
            As with renderBlock, a host should fetch and cache this block before beginning to render,
            if it intends to schedule MIDI events.
    
            This is implemented in the base class. It is nil when musicDeviceOrEffect is NO.
    
            Subclassers should not override. When hosts schedule events via this block, they are
            delivered to the audio unit via the list of AURenderEvents delivered to
            internalRenderBlock.
            
            This bridged to the v2 API MusicDeviceMIDIEvent.
    */
    open var scheduleMIDIEventBlock: AUScheduleMIDIEventBlock? { get }
```
和renderBlock一样,如果主机打算调度MIDI事件的话,应该在开始渲染之前获取并缓存这个块.
这在基类中实现。当musicdevice或effect为NO时，它为nil。
子类不应该覆盖该属性。当主程序通过这个块调度事件时，它们通过发送给internalRenderBlock的AURenderEvents列表 将这个闭包(block)发送到音频单元。
它连接到v2 API MusicDeviceMIDIEvent。

```
/**    @property    MIDIOutputNames
    @brief        Count, and names of, a plug-in's MIDI outputs.
    @discussion
        A plug-in may override this method to inform hosts about its MIDI outputs. The size of the
        array is the number of outputs the audio unit supports. Each item in the array is the name
        of the MIDI output at that index.

        This is bridged to the v2 API property kAudioUnitProperty_MIDIOutputCallbackInfo.
*/
@available(iOS 11.0, *)
open var midiOutputNames: [String] { get }

```

插件可以覆盖这个方法来通知主程序它的MIDI输出。数组的大小是音频单元支持的输出数量。数组中的每一项都是该索引处的MIDI输出的名称。
它被连接到v2 API属性kAudioUnitProperty_MIDIOutputCallbackInfo。

```
/**    @property    providesUserInterface
    @brief        Specifies whether an audio unit provides UI (normally in the form of a view controller).
    @discussion
        Implemented in the framework and should not be overridden by implementators. The
        framework detects whether any subclass has implemented
        `requestViewControllerWithCompletionHandler:` or is implemented by an AU extension whose
        extension point identifier is `com.apple.AudioUnit-UI`. See also
        `requestViewControllerWithCompletionHandler:` in <CoreAudioKit/AUViewController.h>
*/
@available(iOS 11.0, *)
open var providesUserInterface: Bool { get }
```
表明 audioUnit 是否提供UI(一般是以 ViewController 的形式)
这个属性不应重写覆盖, 框架将会检查是否有 AUAudioUnit 的子类或者扩展 id 为`com.apple.AudioUnit-UI`的类实现了`requestViewControllerWithCompletionHandler`方法,具体请参考<CoreAudioKit/AUViewController.h> 的 `requestViewControllerWithCompletionHandler:`


```
// These properties and methods are generally optional.

/**    @property    MIDIOutputEventBlock
    @brief        Block used by the host to access the MIDI output generated by an audio unit.
    @discussion
         The host can set this block and the plug-in can call it in its renderBlock to provide to the
         host the MIDI data associated with the current render cycle.

         This is bridged to the v2 API property kAudioUnitProperty_MIDIOutputCallback.
*/
@available(iOS 11.0, *)
open var midiOutputEventBlock: AUMIDIOutputEventBlock?
```
这个 block 被主程序用于访问或者自己处理由 AU 产生的 midi 输出

```
/**    @property    fullState
    @brief        A persistable snapshot of the audio unit's properties and parameters, suitable for
                saving as a user preset.
    @discussion
        Hosts may use this property to save and restore the state of an audio unit being used in a
        user preset or document. The audio unit should not persist transitory properties such as
        stream formats, but should save and restore all parameters and custom properties.
        
        The base class implementation of this property saves the values of all parameters 
        currently in the parameter tree. A subclass which dynamically produces multiple variants
        of the parameter tree needs to be aware that the serialization method does a depth-first
        preorder traversal of the tree.
        
        Bridged to the v2 property kAudioUnitProperty_ClassInfo.
*/
open var fullState: [String : Any]?
```
一个可持久保存的快照用于保存当前 AU 的属性和参数非常适合用来保存为用户预设
主机可以使用此属性保存和恢复用户预置或文档中使用的音频单元的状态。AU不应该保存诸如流格式之类的临时属性，而应该保存和恢复所有参数和自定义属性。
此属性的基类实现保存参数树中当前所有参数的值。动态生成参数树的多个变体的子类需要注意序列化方法对参数树进行了深度优先的前序遍历。

```

/**    @property    fullStateForDocument
    @brief        A persistable snapshot of the audio unit's properties and parameters, suitable for
                saving in a user's document.
    @discussion
        This property is distinct from fullState in that some state is suitable for saving in user
        presets, while other state is not. For example, a synthesizer's master tuning setting could
        be considered global state, inappropriate for storing in reusable presets, but desirable
        for storing in a document for a specific live performance.
        
        Hosts saving documents should use this property. If the audio unit does not implement it,
        the base class simply sets/gets fullState.

        Bridged to the v2 property kAudioUnitProperty_ClassInfoFromDocument.
*/
open var fullStateForDocument: [String : Any]?
```
一个可持久化的当前 au 的属性和参数的快照, 适合用来保存到文件中(还是 doc 文件夹?)
此属性与fullState的不同之处在于，某些状态适合保存在用户预设中，而其他状态则不适合。例如，合成器的主调优设置可以被认为是全局状态，不适合存储在可重用的预置中，但适合存储在文档中以实现特定的实时性能。
保存文档的主程序应使用此属性。如果AU没有实现它，基类简单地设置/获取fullState。

```
/**    @property    factoryPresets
    @brief        A collection of presets provided by the audio unit's developer.
    @discussion
        A preset provides users of an audio unit with an easily-selectable, fine-tuned set of
        parameters provided by the developer. This property returns all of the available factory presets.

        Bridged to the v2 property kAudioUnitProperty_FactoryPresets.
*/
open var factoryPresets: [AUAudioUnitPreset]? { get }
```
由 au 的开发者提供的预设,简单可选而且是被调优的参数,该方法返回所有的预设

```
/**    @property    userPresets
    @brief        A collection of presets saved by the user
    @discussion
        In addition to factory presets, provided by the audio unit vendor, users have the ability to
        save the values of the parameters of an audio unit into a user preset. These users presets
        can be accessed using this property.

        The default implementation of this method will load the user presets from an internal
        location that might not be directly accessible to the audio unit host application or to the
        audio unit. Instead of accessing this path directly, the audio unit should rely on the
        superclass implementation of this method to retrieve the presets.

        Audio Units are free to override this method to load their user presets via different means
        (e.g. from their iCloud container).
*/
@available(iOS 13.0, *)
open var userPresets: [AUAudioUnitPreset] { get }
```
AU 的供运营商或者使用者,这些预设可以提供相应的参数
此方法的默认实现将从音频单元宿主应用程序或音频单元不能直接访问的内部位置加载用户预置。与直接访问此路径不同，音频单元应该依赖于此方法的超类实现来检索预置。
音频单元可以自由覆盖这个方法，通过不同的方式加载它们的用户预设

```
/**    @method        saveUserPreset:error
    @brief        Persistently save the current state of the audio unit into a userPreset
    @discussion
        The new preset will be added to userPresets and will become selectable by assigning it
        to the currentPreset property.
        If a preset with the provided name already exists then it will be overwritten.

        For user presets, the preset number is required to be negative.
        If a positive number is passed, the sign will be changed to negative.
        If zero is passed, the number will be set to -1.
        These changes will be reflected on the userPreset argument.

        The default implementation of this method will save the user preset to an internal
        location.

        Audio Units are free to override this method to operate on a different location (e.g. their
        iCloud container).
    @param    userPreset
        The preset under which the current state will be saved.
    @param outError
        In the event of a failure, the method will return NO and outError will be set to an 
        NSError, describing the problem. 
        Some possible errors: 
                - domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection
                - domain: NSOSStatusErrorDomain    code: kAudioUnitErr_InvalidFilePath
                - domain: NSOSStatusErrorDomain    code: kAudioUnitErr_MissingKey
    @return
        YES for success. NO in the event of a failure, in which case the error is returned in
        outError.
 */
@available(iOS 13.0, *)
open func saveUserPreset(_ userPreset: AUAudioUnitPreset) throws
```
保存用户的预设,若之前有同名的预设之前的预设将会被覆盖,
对于用户自定义的预设预设号必须为负数,若传入了正数系统将自动将其转换为对应的负数,若传递了 0 则预设号将会被设置为-1
这些预设的默认实现将会把用户预设保存到某个内部位置
AU 可以重写这个方法来讲用户预设保存到其他位置比如 iclould 上
userPreset : 将会被保存的预设
outError : 若保存失败方法将会返回 NO 并且抛出一个错误来描述遇到的问题
Some possible errors: 
//AU 连接异常
        - domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection 
//路径错误
        - domain: NSOSStatusErrorDomain    code: kAudioUnitErr_InvalidFilePath
//看起来像是预设的参数不全
        - domain: NSOSStatusErrorDomain    code: kAudioUnitErr_MissingKey
```
/**    @method        deleteUserPreset:error
    @brief        Remove a user preset.
    @discussion
        The user preset will be removed from userPresets and will be permanently deleted.

        The default implementation of this method will delete the user preset from an internal
        location.

        Audio Units are free to override this method to operate on a different location (e.g. their
        iCloud container).
    @param    userPreset
        The preset to be deleted.
    @param    outError
        In the event of a failure, the method will return NO and outError will be set to an 
        NSError, describing the problem. 
        Some possible errors: 
                - domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection
                - domain: NSPOSIXErrorDomain    code: ENOENT
                - domain: NSOSStatusErrorDomain    code: kAudioUnitErr_InvalidFilePath
    @return
        YES for success. NO in the event of a failure, in which case the error is returned in
        outError.
*/
@available(iOS 13.0, *)
open func deleteUserPreset(_ userPreset: AUAudioUnitPreset) throws
```

- domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection
//看起来像是没有网络连接不能删除 icloud 的预设
- domain: NSPOSIXErrorDomain    code: ENOENT (无此文件)
- domain: NSOSStatusErrorDomain    code: kAudioUnitErr_InvalidFilePath

```
/** @method        presetStateFor:error
    @brief        Retrieve the state stored in a user preset
     @discussion
        This method allows access to the contents of a preset without having to set that preset as
        current. The returned dictionary is assignable to the audio unit's fullState and/or
        fullStateForDocument properties.
 
        Audio units can override this method in order to vend user presets from a different location
        (e.g. their iCloud container).

        In order to restore the state from a user preset, the audio unit should override the setter
        for the currentPreset property and check the preset number to determine the type of preset.
        If the preset number is >= 0 then the preset is a factory preset.
        If the preset number is < 0 then it is a user preset.

        This method can then be called to retrieve the state stored in a user preset and the audio
        unit can assign this to fullState or fullStateForDocument.

    @param    userPreset
        The preset to be selected.
    @param    outError
        In the event of a failure, the method will return nil and outError will be set to an 
        NSError, describing the problem. 
        Some possible errors: 
                - domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection
                - domain: NSPOSIXErrorDomain    code: ENOENT
                - domain: NSCocoaErrorDomain    code: NSCoderReadCorruptError
    @return
        Returns nil if there was an error, otherwise returns a dictionary containing the full state
        of the audio unit saved in the preset.
        For details on the possible keys present in the full state dictionary, please see the
        documentation for kAudioUnitProperty_ClassInfo.
         The minimal set of keys and their type is:    @kAUPresetTypeKey : NSNumber,
                                                    @kAUPresetSubtypeKey : NSNumber,
                                                     @kAUPresetManufacturerKey : NSNumber,
                                                        @kAUPresetVersionKey : NSNumber,
                                                     @kAUPresetNameKey : NSString,
                                                     @kAUPresetNumberKey: NSNumber,
                                                    @kAUPresetDataKey : NSData
*/
@available(iOS 13.0, *)
open func presetState(for userPreset: AUAudioUnitPreset) throws -> [String : Any]
```
遍历当前所有的预设,该方法可以被重写来获取所有的用户设置预设
- domain: NSOSStatusErrorDomain code: kAudioUnitErr_NoConnection
- domain: NSPOSIXErrorDomain    code: ENOENT
- domain: NSCocoaErrorDomain    code: NSCoderReadCorruptError
@kAUPresetTypeKey : NSNumber,
@kAUPresetSubtypeKey : NSNumber,
@kAUPresetManufacturerKey : NSNumber,
@kAUPresetVersionKey : NSNumber,
@kAUPresetNameKey : NSString,
@kAUPresetNumberKey: NSNumber,
@kAUPresetDataKey : NSData


```
/**    @property    supportsUserPresets
    @brief        Specifies whether an audio unit supports loading and saving user presets
    @discussion
        The audio unit should set this property to YES if a user preset can be assigned to
        currentPreset.

        Audio unit host applications should query this property to determine whether the audio unit
        supports user presets.

        Assigning a user preset to the currentPreset property of an audio unit that does not support
        restoring state from user presets may result in incorrect behavior.
*/
@available(iOS 13.0, *)
open var supportsUserPresets: Bool { get }
```
顾名思义可悲重写为 yes 如果可以支持用户预设

```
/**    @property    currentPreset
    @brief        The audio unit's last-selected preset.
    @discussion
        Hosts can let the user select a preset by setting this property. Note that when getting
        this property, it does not reflect whether parameters may have been modified since the
        preset was selected.

        Bridged to the v2 property kAudioUnitProperty_PresentPreset.
*/
open var currentPreset: AUAudioUnitPreset?
```
用户当前选择的预设,主程序可以通过设置该值来让用户选择预设


```
/**    @property    latency
    @brief        The audio unit's processing latency, in seconds.
    @discussion
        This property reflects the delay between when an impulse in the unit's audio unit stream
        arrives in the input vs. output streams. This should reflect the delay due
        to signal processing (e.g. filters, FFT's, etc.), not delay or reverberation which is
        being applied as an effect.
        
        Note that a latency that varies with parameter settings, including bypass, is generally not
        useful to hosts. A host is usually only prepared to add delays before starting to render and
        those delays need to be fixed. A variable delay would introduce artifacts even if the host
        could track it. If an algorithm has a variable latency it should be adjusted upwards to some
        fixed latency within the audio unit. If for some reason this is not possible, then latency
        could be regarded as an unavoidable consequence of the algorithm and left unreported (i.e.
        with a value of 0).

        Bridged to the v2 property kAudioUnitProperty_Latency.
*/
open var latency: TimeInterval { get }
```
这个属性反映了单元音频单元流中的一个脉冲到达输入流与输出流之间的延迟。这应该反映由于信号处理(例如滤波器、FFT等)造成的延迟，而不是作为效果应用的延迟或混响。
请注意，随参数设置(包括旁路)而变化的延迟通常对主机没有用处。一个主机通常只准备在开始渲染前添加延迟，这些延迟需要修正。一个可变的延迟会引入工件，即使主机可以跟踪它。如果一个算法有可变延迟，它应该向上调整到音频单元内的某些固定延迟。如果由于某些原因这是不可能的，那么延迟可以被认为是算法不可避免的结果，而不被报告(例如，值为0)。


```
/**    @property    tailTime
    @brief        The audio unit's tail time, in seconds.
    @discussion
        This property reflects the time interval between when the input stream ends or otherwise
        transitions to silence, and when the output stream becomes silent. Unlike latency, this
        should reflect the duration of a delay or reverb effect.
        
        Bridged to the v2 property kAudioUnitProperty_TailTime.
*/
open var tailTime: TimeInterval { get }
```
输出结束和输入结束的间隔 = 计算本身所用的延时 + 特效自带的延迟 = 输出 end - 输入 end

```
/**    @property    renderQuality
    @brief        Provides a trade-off between rendering quality and CPU load.
    @discussion
        The range of valid values is 0-127.
        
        Bridged to the v2 property kAudioUnitProperty_RenderQuality.
*/
open var renderQuality: Int
```
提供一个计算负载和处理效果之间权衡后的渲染效果

```
/**    @property    shouldBypassEffect
    @brief        Directs an effect to route input directly to output, without any processing.
    @discussion
        Bridged to the v2 property kAudioUnitProperty_BypassEffect.
*/
open var shouldBypassEffect: Bool
```
直接添加效果而不做其他处理

```
/**    @property    canProcessInPlace
    @brief        Expresses whether an audio unit can process in place.
    @discussion
        In-place processing is the ability for an audio unit to transform an input signal to an
        output signal in-place in the input buffer, without requiring a separate output buffer.
        
        A host can express its desire to process in place by using null mData pointers in the output
        buffer list. The audio unit may process in-place in the input buffers. See the discussion of
        renderBlock.
        
        Partially bridged to the v2 property kAudioUnitProperty_InPlaceProcessing; in v3 it is not
        settable.
        
        Defaults to NO. Subclassers can override to return YES.
*/
open var canProcessInPlace: Bool { get }
```
表示 AU 是否可以在 inputbuffer 中就地处理完该数据而不必需要额外的 outputbuffer
主机可以通过在输出缓冲区列表中使用空mData指针来表示它想要就地处理。AU可以在输入缓冲器中就地处理。参见renderBlock的讨论。

```
/**    @property    renderingOffline
    @brief        Communicates to an audio unit that it is rendering offline.
    @discussion
        A host should set this property when using an audio unit in a context where there are no
        realtime deadlines, before asking the unit to allocate render resources. An audio unit may
        respond by using a more expensive signal processing algorithm, or allowing itself to block
        at render time if data being generated on secondary work threads is not ready in time.
        (Normally, in a realtime thread, this data would have to be dropped).

        Bridged to the v2 property kAudioUnitProperty_OfflineRender.
*/
open var isRenderingOffline: Bool
```
与 realtime render 相对应
当主程序在 一个没有实时结束时间的上下文中使用 AU时应当在要求 AU 分配渲染资源之前设置该属性.
AU可能会采用更高消耗的算法处理或者允许他自己在渲染时若在二级线程的资源数据未能及时准备好时阻塞(通常来讲一个实时的线程这些数据可能会被丢弃掉)

```
/**    @property    channelCapabilities
    @brief        Expresses valid combinations of input and output channel counts.
    @discussion
        Elements are NSNumber containing integers; [0]=input count, [1]=output count, [2]=2nd input
        count, [3]=2nd output count, etc.

        An input, output count of (2, 2) signifies that the audio unit can process 2 input channels
        to 2 output channels.
        
        Negative numbers (-1, -2) indicate *any* number of channels. (-1, -1) means any number
        of channels on input and output as long as they are the same. (-1, -2) means any number of
        channels on input or output, without the requirement that the counts are the same.
        
        A negative number less than -2 is used to indicate a total number of channels across every
        bus in that scope, regardless of how many channels are set on any particular bus. For
        example, (-16, 2) indicates that a unit can accept up to 16 channels of input across its
        input busses, but will only produce 2 channels of output.
        
        Zero on either side (though typically input) means "not applicable", because there are no
        elements on that side.

        Bridged to the v2 property kAudioUnitProperty_SupportedNumChannels.
*/
open var channelCapabilities: [NSNumber]? { get }
```
输出合法的通道组合数
若假定返回值为 RET 则有
RET[0]是输入数量 
RET[1]是输出数量 
RET[2]是二级输入数量
RET[3]是二级输出数量

负数(-1，-2)表示任意数量的通道。(-1，-1)表示任意数量的输入和输出通道，只要它们是相同的。
(-1， -2)表示输入或输出上任意数量的通道，不要求计数相同。
无论在任何特定总线上设置了多少个通道，小于-2的负数表示该范围内所有总线上的通道总数。例如，
(-16 ,2)表示一个单元可以通过它的输入总线接受多达16个输入通道，但只能产生2个输出通道。

两边都是零(虽然通常是输入)意味着“不适用”，因为在两边没有元素

```
/**    @property    musicalContextBlock
    @brief        A callback for the AU to call the host for musical context information.
    @discussion
        Note that an audio unit implementation accessing this property should cache it in
        realtime-safe storage before beginning to render.
        
        Bridged to the HostCallback_GetBeatAndTempo and HostCallback_GetMusicalTimeLocation
        callback members in kAudioUnitProperty_HostCallbacks.
*/
open var musicalContextBlock: AUHostMusicalContextBlock?
```
一个提供给主程序处理音乐上下文信息的回调

```
/**    @property    transportStateBlock
    @brief        A callback for the AU to call the host for transport state information.
    @discussion
        Note that an audio unit implementation accessing this property should cache it in
        realtime-safe storage before beginning to render.
        
        Bridged to the HostCallback_GetTransportState and HostCallback_GetTransportState2
        callback members in kAudioUnitProperty_HostCallbacks.
*/
open var transportStateBlock: AUHostTransportStateBlock?
```
一个为主程序提供传输状态信息的回调

```
/**    @property    contextName
    @brief        Information about the host context in which the audio unit is connected, for display
                in the audio unit's view.
    @discussion
        For example, a host could set "track 3" as the context, so that the audio unit's view could
        then display to the user "My audio unit on track 3".

        Bridged to the v2 property kAudioUnitProperty_ContextName.
*/
open var contextName: String?
```
主程序为 AU 设置 AU 的 UI显示的主程序的上下文信息
例如，主机可以设置“track 3”作为上下文，这样AU的UI就可以显示“My audio unit on track 3”给用户。

```
/**    @property    supportsMPE
    @brief        Specifies whether an audio unit supports Multi-dimensional Polyphonic Expression.
    @discussion
        Bridged to the v2 property kAudioUnitProperty_SupportsMPE.
*/
@available(iOS 10.0, *)
open var supportsMPE: Bool { get }
```
指定音频单元是否支持多维复调表达式。 ??? //todo

```
/**    @property    channelMap
    @brief        Specify a mapping of input channels to output channels.
    @discussion
        Converter and input/output audio units may support re-ordering or splitting of input
        channels to output channels. The number of channels in the channel map is the number of
        channels of the destination (output format). The channel map entries contain a channel
        number of the source channel that should be mapped to that destination channel. If -1 is
        specified, then that destination channel will not contain any channel from the source (so it
        will be silent).
        
        If the property value is nil, then the audio unit does not support this property.
 
        Bridged to the v2 property kAudioOutputUnitProperty_ChannelMap.
*/
@available(iOS 10.0, *)
open var channelMap: [NSNumber]?
```
指定一个路由将指定的通道的输入送到另一个通道输出
转换器和输入/输出音频单元可以支持重新排序或将单个输入通道输出到 多个到输出通道。通道映射中的通道数量是目标通道的数量(输出格式)。通道映射项包含源通道的通道号，源通道应该映射到该目标通道。如果指定了-1，那么目标通道将不包含来自源的任何通道(因此它将是静默的)。
如果属性值为nil，那么音频单元不支持这个属性。

```
/**    @method        profileStateForCable:channel:
    @brief        Given a MIDI cable and channel number, return the supported MIDI-CI Profiles.
    @param cable
        The virtual MIDI cable for which the profiles are requested.
    @param channel
        The MIDI channel for which the profiles are requested.
    @return
        A MIDICIProfileState object containing all the supported MIDI-CI profiles for this channel
        on this cable.
*/
@available(iOS 12.0, *)
open func profileState(forCable cable: UInt8, channel: MIDIChannelNumber) -> MIDICIProfileState
```
给定一个 midi 线缆和一个声道返回支持的MIDICIProfileState
{
/**
     @class    MIDICIProfileState
     @brief  Lists the enabled and disabled profiles for a MIDI channel or port on a device.
*/
@available(iOS 12.0, *)
open class MIDICIProfileState : NSObject, NSSecureCoding {

    open var midiChannel: MIDIChannelNumber { get }

    open var enabledProfiles: [MIDICIProfile] { get }

    open var disabledProfiles: [MIDICIProfile] { get }

    
    @available(iOS 14.0, *)
    public init(channel midiChannelNum: MIDIChannelNumber, enabledProfiles enabled: [MIDICIProfile], disabledProfiles disabled: [MIDICIProfile])

    @available(iOS, introduced: 12.0, deprecated: 100000)
    public init(enabledProfiles enabled: [MIDICIProfile], disabledProfiles disabled: [MIDICIProfile])
}


// =================================================================================================


/**
     @class        MIDICIProfile
     @abstract      An NSObject representing Capability Inquiry profile. MIDI-CI profiles describe a mapping
                of MIDI messages to specific sounds and synthesis behaviors, e.g. General MIDI, a drawbar organ,
                etc. A MIDI-CI profile may be a standard registered profile or vendor-specific.
 
                                Standard Profile                Vendor-Specific Profile
                Profile ID Byte 1:    0x7E Standard Profile            Manufacturer SysEx ID 1 Profile
                Profile ID Byte 2:    Profile Bank                Manufacturer SysEx ID 2 Profile
                Profile ID Byte 3:    Profile Number                Manufacturer SysEx ID 3 Profile
                Profile ID Byte 4:    Profile Version                Manufacturer-specific Info
                Profile ID Byte 5:    Profile Level                Manufacturer-specific Info
*/
@available(iOS 12.0, *)
open class MIDICIProfile : NSObject, NSSecureCoding {

    
    /// An NSString describing the profile.
    open var name: String { get }

    
    /// The unique 5-byte profile identifier representing the profile.
    open var profileID: Data { get } // always 5 bytes

    
    @available(iOS 14.0, *)
    public init(data: Data)

    public init(data: Data, name inName: String)
}
}

```
/**    @method        enableProfile:cable:onChannel:error:
    @brief        Enable a MIDI-CI Profile on the specified cable/channel.
    @param    profile
        The MIDI-CI profile to be enabled.
    @param cable
        The virtual MIDI cable.
    @param channel
        The MIDI channel.
    @param outError
        Returned in the event of failure.
    @return
        YES for success. NO in the event of a failure, in which case the error is returned
        in outError.
*/
@available(iOS 12.0, *)
open func enable(_ profile: MIDICIProfile, cable: UInt8, onChannel channel: MIDIChannelNumber) throws
```
为某一个声道或者线缆激活指定的MIDICIProfile(MIDI消息到特定声音和合成行为的映射，例如通用MIDI、拖弦风琴等等。)

```
/**    @method        disableProfile:cable:onChannel:error:
    @brief        Disable a MIDI-CI Profile on the specified cable/channel.
    @param    profile
        The MIDI-CI profile to be disabled.
    @param cable
        The virtual MIDI cable.
    @param channel
        The MIDI channel.
    @param outError
        Returned in the event of failure.
    @return
        YES for success. NO in the event of a failure, in which case the error is returned
        in outError.
*/
@available(iOS 12.0, *)
open func disableProfile(_ profile: MIDICIProfile, cable: UInt8, onChannel channel: MIDIChannelNumber) throws
```
顾名思义

```
/**    @property    profileChangedBlock
    @brief        A block called when a device notifies that a MIDI-CI profile has been enabled or 
                disabled.
    @discussion
        Since enabling / disabling MIDI-CI profiles is an asynchronous operation, the host can set 
        this block and the audio unit is expected to call it every time the state of a MIDI-CI 
        profile has changed.
*/
@available(iOS 12.0, *)
open var profileChangedBlock: AUMIDICIProfileChangedBlock?
```
回调顾名思义
启动或者关闭一个 profile 可能是异步操作,主程序可以设置这个回调,当profile 改变时会 调用这个回调

```
/**    @typedef    AUInputHandler
    @brief        Block to notify the client of an I/O unit that input is available.
    @param actionFlags
        Pointer to action flags.
    @param timestamp
        The HAL time at which the input data was captured. If there is a sample rate conversion
        or time compression/expansion downstream, the sample time will not be valid.
    @param frameCount
        The number of sample frames of input available.
    @param inputBusNumber
        The index of the input bus from which input is available.
    @discussion    The input data is obtained by calling the render block of the audio unit.
                The AUAudioUnit is not provided since it is not safe to message an Objective C 
                object in a real time context.
*/
public typealias AUInputHandler = (UnsafeMutablePointer<AudioUnitRenderActionFlags>, UnsafePointer<AudioTimeStamp>, AUAudioFrameCount, Int) -> Void
```
向 IO单元发送通知,现在输入可用
actionFlags : AudioUnitRenderActionFlags
timestamp : AudioTimeStamp 
frameCount : 输入需要的采样帧数
inputBusNumber : 指出哪一条总线可用

# AUAudioUnit extension

```
/**    @property    canPerformInput
    @brief        Whether the I/O device can perform input.
*/
open var canPerformInput: Bool { get }
```
表示 io 设备是否具有可以输入

```
/**    @property    canPerformOutput
    @brief        Whether the I/O device can perform output.
*/
open var canPerformOutput: Bool { get }
```
表示  io 设备是否具可以输出

```

/**    @property    inputEnabled
    @brief        Flag enabling audio input from the unit.
    @discussion    Input is disabled by default. This must be set to YES if input audio is desired. 
                Setting to YES will have no effect if canPerformInput is false.
*/
open var isInputEnabled: Bool
```
表示输入设备是否开启
如果需要使用输入设备需要手动打开输入设备,若当前的 io 设备无法输入,则设置无效

```
/**    @property    outputEnabled
    @brief        Flag enabling audio output from the unit.
    @discussion    Output is enabled by default.
                Setting to YES will have no effect if canPerformOutput is false.
*/
open var isOutputEnabled: Bool
```
表示输出设备是否开启
细节同上

```
/**    @property    outputProvider
    @brief        The block that the output unit will call to get audio to send to the output.
    @discussion    This block must be set if output is enabled.
*/
open var outputProvider: AURenderPullInputBlock?
```
一个输出单元调用来获得想要输出的音频的 block 若该单元开启了输出则必须设置这个 block

```
/**    @property    inputHandler
    @brief        The block that the output unit will call to notify when input is available.
    @discussion    See discussion for AUInputHandler.
*/
open var inputHandler: AUInputHandler?
```
当单元输入可用通知输出单元调用该 block

```
// TARGET_OS_IPHONE

/**    @property    running
    @brief        The audio device's running state.
*/
@available(iOS 11.0, *)
open var isRunning: Bool { get }
```
音频设备当前是否正在运行

```
/**    @method        startHardwareAndReturnError:
    @brief        Starts the audio hardware.
    @param outError
        Returned in the event of failure.
*/
open func startHardware() throws
```
开启硬件//todo

```
/**    @method        stopHardware
    @brief        Stops the audio hardware.
*/
open func stopHardware()
```
关闭硬件//todo


## AUAudioUnitBusArray

所有的输入输出的音频轨
通过在这个对象上使用KVO，主机可以通过有总线观察一个总线属性，而不必在每个单独的总线上观察它。(可以向单个总线添加侦听器，但这意味着必须观察总线计数的变化，并相应地添加/删除observer。
另外，NSArray的addObserver:toObjectsAtIndexes:forKeyPath: context:是有问题的;
它不允许单个对象覆盖KVO，因此在扩展进程中代理总线的总线不会得到消息。)

一些音频单元(例如混频器)通过子类化支持可变数量的总线。当总线计数改变时，一个KVO通知被发送到" inputbus "或" outputbus "，视情况而定。

子类的实现者也应该看 AUAudioUnitBusImplementation 类扩展。

```
/**    @method        initWithAudioUnit:busType:busses:
    @brief        Initializes by making a copy of the supplied bus array.
*/
public init(audioUnit owner: AUAudioUnit, busType: AUAudioUnitBusType, busses busArray: [AUAudioUnitBus])
```
AUAudioUnitBusType     
- case input = 1
- case output = 2
AUAudioUnitBus : 类后面介绍
复制一份音频总线

```
/**    @method        initWithAudioUnit:busType:
    @brief        Initializes an empty bus array.
*/
public convenience init(audioUnit owner: AUAudioUnit, busType: AUAudioUnitBusType)
```
建立一个空的音频总线数组


```
/**    @property    count
*/
open var count: Int { get }
```
包含的音频轨的数量

```
/**    @method        objectAtIndexedSubscript:
*/
open subscript(index: Int) -> AUAudioUnitBus { get }
```
某个音频轨

```
/**    @property    countChangeable
    @brief        Whether the array can have a variable number of busses.
    @discussion
        The base implementation returns false.
*/
open var isCountChangeable: Bool { get }
```
音频轨的数量是否可以改变
基础实现是不允许改动

```
/**    @property    setBusCount:error:
    @brief        Change the number of busses in the array.
*/
open func setBusCount(_ count: Int) throws
```
改变音频轨的数量

```
/**    @method        addObserverToAllBusses:forKeyPath:options:context:
    @brief        Add a KVO observer for a property on all busses in the array.
*/
open func addObserver(toAllBusses observer: NSObject, forKeyPath keyPath: String, options: NSKeyValueObservingOptions = [], context: UnsafeMutableRawPointer?)
```
```
/**    @method        removeObserverFromAllBusses:forKeyPath:context:
    @brief        Remove a KVO observer for a property on all busses in the array.
*/
open func removeObserver(fromAllBusses observer: NSObject, forKeyPath keyPath: String, context: UnsafeMutableRawPointer?)
```

```
/// The audio unit that owns the bus.
unowned(unsafe) open var ownerAudioUnit: AUAudioUnit { get }
```
```
/// Which bus array this is (input or output).
open var busType: AUAudioUnitBusType { get }
```
以上为不用翻译也不会造成歧义的

## AUAudioUnitBus

输入输出在 AU 上的连接点

```
/**    @property    format
    @brief        The audio format and channel layout of audio being transferred on the bus.
    @discussion
        Bridged to the v2 property kAudioUnitProperty_StreamFormat.
*/
open var format: AVAudioFormat { get }
```
传递给 bus 的音频格式和声道布局

```
/**    @property    setFormat:error:
    @brief        Sets the bus's audio format.
    @discussion
        Audio units can generally be expected to support AVAudioFormat's standard format
        (deinterleaved 32-bit float), at any sample rate. Channel counts can be more complex;
        see AUAudioUnit.channelCapabilities.
*/
open func setFormat(_ format: AVAudioFormat) throws
```
为音频轨设置音频格式
一般认为 AU 支持任何码率的 AVAudioFormat 的标准格式(去交错的 32 位浮点数)
而声道可能会更加复杂
请参考 AUAudioUnit.channelCapabilities.

```
/** @property    shouldAllocateBuffer
    @brief        Controls the audio unit's allocation strategy for a bus.
    @discussion
        Hosts can set this flag to communicate whether an audio unit should allocate its own buffer.
        By default this flag is set to true.

        On the output side, shouldAllocateBuffer=false means the AU can assume that it will be
        called with non-null output buffers. If shouldAllocateBuffer=true (the default), the AU must
        be prepared to be called with null pointers and replace them with pointers to its internally
        allocated buffer.

        On the input side, shouldAllocateBuffer=false means the AU can pull for input using a buffer
        list with null buffer pointers, and assume that the pull input block will provide pointers.
        If shouldAllocateBuffer=true (the default), the AU must pull with non-null pointers while
        still being prepared for the source to replace them with pointers of its own.

        Bridged to the v2 property kAudioUnitProperty_ShouldAllocateBuffer.
*/
@available(iOS 11.0, *)
open var shouldAllocateBuffer: Bool
```
表示 au 对音频轨的内存分配的控制策略
主机可以设置这个标志来交流音频单元是否应该分配它自己的缓冲区。默认情况下，这个标志被设置为true。

在输出端，shouldAllocateBuffer=false意味着AU可以假设它将被非空输出缓冲区调用。如果shouldAllocateBuffer=true(默认值)，AU必须准备好被null指针调用，并用指向内部分配缓冲区的指针替换它们。

在输入端，shouldAllocateBuffer=false意味着AU可以使用带有空缓冲指针的缓冲列表来拉入输入，并且假设拉入输入块将提供指针。
如果shouldAllocateBuffer=true(默认值)，AU必须使用非空指针拉取输入，同时还在为输入源准备，以便用自己的指针替换它们。

```
/**    @property    enabled
    @brief        Whether the bus is active.
    @discussion
        Hosts must enable input busses before using them. The reason for this is to allow a unit
        such as a mixer to be prepared to render a large number of inputs, but avoid the work
        of preparing to pull inputs which are not in use.
        
        Bridged to the v2 properties kAudioUnitProperty_MakeConnection and
        kAudioUnitProperty_SetRenderCallback.
*/
open var isEnabled: Bool
```
当前音频轨是否被激活
主程序必须在使用输入音频轨之前打开该音频轨.
因为当一个音频处理单元将要去准备渲染大量输入时,需要音频的输入(tm 废话)

```
/**    @property    name
    @brief        A name for the bus. Can be set by host.
*/
open var name: String?
```
音频轨的名称可由主程序设定


```
/** @property   index
    @brief      The index of this bus in the containing array.
*/
open var index: Int { get }
```
当前音频轨在音频轨组里面的序号

```
/** @property   busType
    @brief      The AUAudioUnitBusType.
*/
open var busType: AUAudioUnitBusType { get }
```
是输入还是输出

```
/** @property   ownerAudioUnit
    @brief      The audio unit that owns the bus.
*/
unowned(unsafe) open var ownerAudioUnit: AUAudioUnit { get }
```
拥有此音频轨的 AU

```
/**    @property    supportedChannelLayoutTags
    @discussion
        This is an array of NSNumbers representing AudioChannelLayoutTag.
*/
open var supportedChannelLayoutTags: [NSNumber]? { get }
```

```
/**    @property    contextPresentationLatency
@brief        Information about latency in the audio unit's processing context.
@discussion
    This should not be confused with the audio unit's latency property, where the audio unit
    describes to the host any processing latency it introduces between its input and its output.
    
    A host may set this property to describe to the audio unit the presentation latency of its
    input and/or output audio data. Latency is described in seconds. A value of zero means
    either no latency or an unknown latency.
    
    A host should set this property on each active bus, since, for example, the audio routing
    path to each of multiple output busses may differ.
    
    For input busses:
        Describes how long ago the audio arriving on this bus was acquired. For instance, when
        reading from a file to the first audio unit in a chain, the input presentation latency
        is zero. For audio input from a device, this initial input latency is the presentation
        latency of the device itself, i.e. the device's safety offset and latency.
        
        A second chained audio unit's input presentation latency will be the input presentation
        latency of the first unit, plus the processing latency of the first unit.
        
    For output busses:
        Describes how long it will be before the output audio of an audio unit is presented. For
        instance, when writing to a file, the output presentation latency of the last audio unit
        in a chain is zero. When the audio from that audio unit is to be played to a device,
        then that initial presentation latency will be the presentation latency of the device
        itself, which is the I/O buffer size, plus the device's safety offset and latency
        
        A previous chained audio unit's output presentation latency is the last unit's
        presentation latency plus its processing latency.
        
    So, for a given audio unit anywhere within a mixing graph, the input and output presentation latencies describe to that unit how long from the moment of generation it has taken for its input to arrive, and how long it will take for its output to be presented.
    
    Bridged to the v2 property kAudioUnitProperty_PresentationLatency.
*/
open var contextPresentationLatency: TimeInterval
```
在 AU 的上下文中的延迟信息
此延迟不应与描述 AU 处理延迟的 AU 的latency属性混淆,
主机可以设置此属性来向音频单元描述其输入和/或输出音频数据的呈现延迟。延迟时间以秒为单位描述。值为0意味着没有延迟或未知延迟。是要求的延迟(如要求一段音频几秒后在输出)

主机应该在每个活动音频轨上设置这个属性，因为，例如，到每个输出总线的音频的路径可能不同。

对输入总线胃炎:
描述多久以前的音频到达了这条音轨上被获取。例如，当从文件读取到数据链中的数据到第一个AU时，输入表示延迟为零。对于来自设备的音频输入，这个初始输入延迟是设备本身的呈现延迟，即设备的安全偏移和延迟。

下一个音频单元的输入呈现延迟将为第一单元的输入呈现延迟加上第一单元的处理延迟。

对于输出总线:
描述音频单元的输出音频显示前需要多长时间。例如，当写入文件时，链中最后一个音频单元的输出呈现延迟为零。当音频单元的音频要播放到设备上时，那么初始的呈现延迟将是设备本身的呈现延迟，即I/O缓冲区的大小，加上设备的安全偏移和延迟

前一个音频单元的输出呈现延迟是最后一个单元的呈现延迟加上它的处理延迟。

{所以，对于进行混音单音频单元,input and output presentation latencies
将描述该单元从生成时刻到输入到达所花费的时间，以及输出呈现所花费的时间。}翻译的有问题后面慢慢翻译

## AUAudioUnitPreset
AU提供给实现者的一些列参数,来制造一系列有用的声音或者起点?

```
/**    @property    number
    @brief        The preset's unique numeric identifier.
*/
open var number: Int
```
```
/**    @property    name
    @brief        The preset's name.
*/
open var name: String
```
预设的名字和 id
